# ğŸš€ Modular Reinforcement Learning Framework

PyTorch ê¸°ë°˜ì˜ ëª¨ë“ˆí™”ëœ ê°•í™”í•™ìŠµ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. 8ê°œì˜ ì£¼ìš” ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ CartPole, LunarLander, MuJoCo í™˜ê²½ì—ì„œ ì²´ê³„ì ìœ¼ë¡œ ì‹¤í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“‹ êµ¬í˜„ëœ ì•Œê³ ë¦¬ì¦˜

### ğŸ¯ On-Policy ì•Œê³ ë¦¬ì¦˜
- **PPO (Proximal Policy Optimization)** - Clipped objective, GAE ì§€ì›
- **TRPO (Trust Region Policy Optimization)** - Natural policy gradients, KL divergence constraints
- **A2C (Advantage Actor-Critic)** - Actor-Critic ì•„í‚¤í…ì²˜, entropy regularization
- **REINFORCE** - ìˆœìˆ˜ Monte Carlo policy gradient

### ğŸ¯ Off-Policy ì•Œê³ ë¦¬ì¦˜
- **SAC (Soft Actor-Critic)** - Maximum entropy RL, automatic temperature tuning
- **DDPG (Deep Deterministic Policy Gradient)** - Deterministic policy gradient, target networks
- **TD3 (Twin Delayed Deep Deterministic Policy Gradient)** - DDPG ê°œì„ , twin critics
- **SQL (Soft Q-Learning)** - Maximum entropy Q-learning, ì—°ì†/ì´ì‚° í–‰ë™ê³µê°„ ì§€ì›

## ğŸŒ ì§€ì› í™˜ê²½

| í™˜ê²½ | íƒ€ì… | ìƒíƒœ ì°¨ì› | í–‰ë™ ì°¨ì› | ì„¤ëª… |
|------|------|-----------|-----------|------|
| **CartPole-v1** | ì´ì‚° | 4 | 2 | ì¹´íŠ¸-í´ ê· í˜• ì œì–´ |
| **LunarLanderContinuous-v3** | ì—°ì† | 8 | 2 | ë‹¬ ì°©ë¥™ì„  ì œì–´ |
| **HalfCheetah-v4** | ì—°ì† | 17 | 6 | MuJoCo ì¹˜íƒ€ ë¡œë´‡ |

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •
```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd rl_framework

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# wandb ë¡œê·¸ì¸ (ì„ íƒì )
wandb login
```

### 2. ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰
```bash
# PPOë¡œ CartPole í•™ìŠµ
python -m main train --config config/cartpole/ppo.yaml

# SACë¡œ LunarLander í•™ìŠµ
python -m main train --config config/lunarlander/sac.yaml

# TD3ë¡œ HalfCheetah í•™ìŠµ
python -m main train --config config/halfcheetah/td3.yaml
```

### 3. ë©€í‹° ì‹œë“œ ì‹¤í—˜ ì‹¤í–‰
```bash
# 5ê°œ ì‹œë“œë¡œ ì•ˆì •ì ì¸ ê²°ê³¼ íšë“
python -m main multi --config config/cartpole/ppo.yaml --seeds 0 1 2 3 4

# ë³‘ë ¬ ì‹¤í–‰ (3ê°œ ì›Œì»¤)
python -m main multi --config config/lunarlander/sac.yaml --seeds 0 1 2 3 4 --num_workers 3
```

## ğŸ¬ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ì‹¤í—˜

### ğŸŒ™ Overnight ì‹¤í—˜ (í™˜ê²½ë³„ ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ ìë™ ì‹¤í–‰)

#### ğŸ® CartPole í™˜ê²½ (ì´ì‚° í–‰ë™ê³µê°„)
```bash
# 8ê°œ ì•Œê³ ë¦¬ì¦˜ ìˆœì°¨ ì‹¤í–‰: PPO, TRPO, A2C, REINFORCE, SAC, TD3, DDPG, SQL
bash scripts/overnight/cartpole_overnight.sh
```
**í™˜ê²½ íŠ¹ì§•:**
- ğŸ¯ **ë‚œì´ë„**: ì´ˆê¸‰ (ê°„ë‹¨í•œ ì œì–´ ë¬¸ì œ)
- ğŸ® **í–‰ë™ ê³µê°„**: ì´ì‚° (ì™¼ìª½/ì˜¤ë¥¸ìª½)
- ğŸ“Š **ëª©í‘œ ì ìˆ˜**: 475ì  ì´ìƒ (500ì  ë§Œì )
- â±ï¸ **ì—í”¼ì†Œë“œ ê¸¸ì´**: ìµœëŒ€ 500ìŠ¤í…

**ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ëŠ¥ ì˜ˆì¸¡:**
- **ğŸ¥‡ ìµœê³  ì„±ëŠ¥**: PPO, A2C (ì´ì‚° í–‰ë™ íŠ¹í™”)
- **ğŸ¥ˆ ì•ˆì •ì  ì„±ëŠ¥**: TRPO, REINFORCE
- **ğŸ¥‰ ë„ì „ì **: SAC, SQL (ì´ì‚° ë³€í™˜ ë²„ì „)
- **âš ï¸ ì£¼ì˜**: DDPG, TD3 (ì—°ì†â†’ì´ì‚° ë³€í™˜, ì„±ëŠ¥ ì œí•œì )
- **â° ì˜ˆìƒ ì‹œê°„**: 6-8ì‹œê°„ (ë¹ ë¥¸ ìˆ˜ë ´)

#### ğŸŒ™ LunarLander í™˜ê²½ (ì—°ì† í–‰ë™ê³µê°„)
```bash
# 8ê°œ ì•Œê³ ë¦¬ì¦˜ ìˆœì°¨ ì‹¤í–‰: PPO, TRPO, A2C, REINFORCE, DDPG, TD3, SAC, SQL
bash scripts/overnight/lunarlander_overnight.sh
```
**í™˜ê²½ íŠ¹ì§•:**
- ğŸš€ **ë‚œì´ë„**: ì¤‘ê¸‰ (2ì°¨ì› ì—°ì† ì œì–´)
- ğŸ® **í–‰ë™ ê³µê°„**: ì—°ì† (ë©”ì¸ ì—”ì§„, ì¢Œìš° ì—”ì§„)
- ğŸ“Š **ëª©í‘œ ì ìˆ˜**: 200ì  ì´ìƒ (ì•ˆì „ ì°©ë¥™)
- â±ï¸ **ì—í”¼ì†Œë“œ ê¸¸ì´**: ìµœëŒ€ 1000ìŠ¤í…

**ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ëŠ¥ ì˜ˆì¸¡:**
- **ğŸ¥‡ ìµœê³  ì„±ëŠ¥**: SAC, TD3 (ì—°ì† ì œì–´ íŠ¹í™”)
- **ğŸ¥ˆ ì•ˆì •ì  ì„±ëŠ¥**: PPO, DDPG (ì •ì±…/ê°€ì¹˜ ê¸°ë°˜)
- **ğŸ¥‰ ì¼ë°˜ì **: TRPO, A2C (ë²”ìš© ì•Œê³ ë¦¬ì¦˜)
- **ğŸ”¬ ì‹¤í—˜ì **: SQL (ìƒˆë¡œìš´ ì ‘ê·¼)
- **âš ï¸ ë„ì „ì **: REINFORCE (ë†’ì€ ë¶„ì‚°)
- **â° ì˜ˆìƒ ì‹œê°„**: 8-10ì‹œê°„ (ì¤‘ê°„ ìˆ˜ë ´ ì†ë„)

#### ğŸƒ HalfCheetah í™˜ê²½ (ê³ ì°¨ì› ì—°ì† í–‰ë™ê³µê°„)  
```bash
# 8ê°œ ì•Œê³ ë¦¬ì¦˜ ìˆœì°¨ ì‹¤í–‰: PPO, TRPO, A2C, REINFORCE, DDPG, TD3, SAC, SQL
bash scripts/overnight/halfcheetah_overnight.sh
```
**í™˜ê²½ íŠ¹ì§•:**
- ğŸ¯ **ë‚œì´ë„**: ê³ ê¸‰ (6ì°¨ì› ê³ ì°¨ì› ì—°ì† ì œì–´)
- ğŸ® **í–‰ë™ ê³µê°„**: ì—°ì† (6ê°œ ê´€ì ˆ í† í¬ ì œì–´)
- ğŸ“Š **ëª©í‘œ ì ìˆ˜**: 4000ì  ì´ìƒ (ìµœëŒ€ ì†ë„ ë‹¬ì„±)
- â±ï¸ **ì—í”¼ì†Œë“œ ê¸¸ì´**: ìµœëŒ€ 1000ìŠ¤í…
- ğŸ§  **ìƒíƒœ ì°¨ì›**: 17ì°¨ì› (ìœ„ì¹˜, ì†ë„, ê°ë„ ë“±)

**ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ëŠ¥ ì˜ˆì¸¡:**
- **ğŸ¥‡ ìµœê³  ì„±ëŠ¥**: SAC, TD3 (ê³ ì°¨ì› ì—°ì† ì œì–´ íŠ¹í™”)
- **ğŸ¥ˆ ê°•ë ¥í•œ ì„±ëŠ¥**: PPO, TRPO (ì •ì±… ê¸°ë°˜ ì•ˆì •ì„±)
- **ğŸ¥‰ ì¼ë°˜ì **: DDPG (ê¸°ë³¸ì  ì—°ì† ì œì–´)
- **ğŸ”¬ ë„ì „ì **: A2C, SQL, REINFORCE (ë³µì¡í•œ í™˜ê²½ ëŒ€ì‘)
- **â° ì˜ˆìƒ ì‹œê°„**: 12-15ì‹œê°„ (ë³µì¡í•œ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜)

**íŠ¹ì§•:**
- âœ… ìë™ GPU ê°ì§€ ë° ì„¤ì •
- âœ… wandb ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
- âœ… ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ê³µ/ì‹¤íŒ¨ ì¶”ì 
- âœ… 10ì´ˆ ê°„ê²© ìë™ ì‹¤í–‰
- âœ… ê²°ê³¼ ìš”ì•½ ì¶œë ¥

### ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

#### ì•Œê³ ë¦¬ì¦˜ë³„ ì „ìš© íŠœë‹ ìŠ¤í¬ë¦½íŠ¸

```bash
# PPO í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (27ê°œ ì¡°í•©)
# íŒŒë¼ë¯¸í„°: learning_rate, clip_ratio, gae_lambda
bash scripts/tuning/ppo_tuning.sh cartpole

# SAC í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (27ê°œ ì¡°í•©)
# íŒŒë¼ë¯¸í„°: learning_rate, batch_size, tau
bash scripts/tuning/sac_tuning.sh lunarlander

# DDPG í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (81ê°œ ì¡°í•©)
# íŒŒë¼ë¯¸í„°: lr_actor, lr_critic, tau, ou_sigma
bash scripts/tuning/ddpg_tuning.sh halfcheetah

# TRPO í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (27ê°œ ì¡°í•©)
# íŒŒë¼ë¯¸í„°: learning_rate, max_kl, damping
bash scripts/tuning/trpo_tuning.sh lunarlander

# TD3 í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (27ê°œ ì¡°í•©)
# íŒŒë¼ë¯¸í„°: lr_actor, policy_noise, policy_freq
bash scripts/tuning/td3_tuning.sh halfcheetah

# SQL í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (27ê°œ ì¡°í•©)
# íŒŒë¼ë¯¸í„°: learning_rate, temperature, batch_size
bash scripts/tuning/sql_tuning.sh cartpole
```

#### ë²”ìš© íŠœë‹ ìŠ¤í¬ë¦½íŠ¸

```bash
# ê¸°ë³¸ í•™ìŠµë¥  ê·¸ë¦¬ë“œ ì„œì¹˜
bash scripts/tuning/generic_tuning.sh ppo cartpole

# ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„° íŒŒì¼ ì‚¬ìš©
bash scripts/tuning/generic_tuning.sh ppo cartpole scripts/tuning/example_params.txt
```

**ì‚¬ìš©ì ì •ì˜ íŒŒë¼ë¯¸í„° íŒŒì¼ ì˜ˆì‹œ:**
```txt
# scripts/tuning/custom_params.txt
lr_actor=1e-4 clip_ratio=0.1 gae_lambda=0.9
lr_actor=3e-4 clip_ratio=0.2 gae_lambda=0.95
lr_actor=1e-3 clip_ratio=0.3 gae_lambda=0.98
```

### ğŸ® ì‹œë®¬ë ˆì´ì…˜ ë° ì‹œê°í™”

#### í•™ìŠµëœ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
```bash
# í•™ìŠµëœ ëª¨ë¸ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
bash scripts/run_simulations.sh
```

âš ï¸ **ì£¼ì˜ì‚¬í•­**: ì‹œë®¬ë ˆì´ì…˜ì€ GUIê°€ í•„ìš”í•©ë‹ˆë‹¤. **ê°€ìƒë¨¸ì‹ (VM)ì—ì„œëŠ” ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰**í•˜ì„¸ìš”.

#### ê²°ê³¼ ì‹œê°í™”
```bash
# í•™ìŠµ ê³¡ì„  í”Œë¡¯
python -m main plot --results_dir results/cartpole_ppo --plot_type learning_curves

# ìŠ¤í… ê¸°ë°˜ í•™ìŠµ ê³¡ì„  (ì•Œê³ ë¦¬ì¦˜ ê³µì • ë¹„êµ)
python -m main plot --results_dir results/cartpole_ppo --plot_type step_learning_curves

# ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ (ì—í”¼ì†Œë“œ ê¸°ë°˜)
python -m main plot --plot_type comparison \
  --comparison_dirs results/cartpole_ppo results/cartpole_sac \
  --labels PPO SAC

# ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ (ìŠ¤í… ê¸°ë°˜ - ê¶Œì¥)
python -m main plot --plot_type step_comparison \
  --comparison_dirs results/cartpole_ppo results/cartpole_sac \
  --labels PPO SAC
```

## ğŸ“Š ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### wandb (Weights & Biases) ì—°ë™

#### ì„¤ì • ë°©ë²•
1. **ê³„ì • ìƒì„±**: [wandb.ai](https://wandb.ai)ì—ì„œ ë¬´ë£Œ ê³„ì • ìƒì„±
2. **ë¡œê·¸ì¸**: 
   ```bash
   wandb login
   # API í‚¤ ì…ë ¥ (wandb.ai/authorizeì—ì„œ í™•ì¸)
   ```
3. **ìƒíƒœ í™•ì¸**:
   ```bash
   wandb status
   ```

#### wandb í™œì„±í™”
config íŒŒì¼ì—ì„œ wandb ì„¤ì •ì„ í™œì„±í™”í•˜ì„¸ìš”:

```yaml
# config/í™˜ê²½/ì•Œê³ ë¦¬ì¦˜.yaml
logging:
  use_wandb: true
  wandb_project: "rl-framework-cartpole"  # í”„ë¡œì íŠ¸ ëª…
  wandb_entity: "your-username"           # ì‚¬ìš©ìëª… ë˜ëŠ” íŒ€ëª…
  enable_step_logging: true
  step_log_interval: 1000                 # 1000 ìŠ¤í…ë§ˆë‹¤ ë¡œê¹…
```

#### wandb ëŒ€ì‹œë³´ë“œ í™•ì¸
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì‹¤í—˜ ì‹¤í–‰ ì¤‘ í„°ë¯¸ë„ì— í‘œì‹œë˜ëŠ” wandb URL í´ë¦­
- **í”„ë¡œì íŠ¸ë³„ ì ‘ê·¼**:
  - CartPole: `rl-framework-cartpole`
  - LunarLander: `rl-framework-lunarlander`
  - HalfCheetah: `rl-framework-mujoco-halfcheetah`

#### wandbì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­
- **Episode Reward**: ì—í”¼ì†Œë“œë³„ ë³´ìƒ
- **Step Reward**: ìŠ¤í…ë³„ ë³´ìƒ (ì•Œê³ ë¦¬ì¦˜ ê³µì • ë¹„êµìš©)
- **Loss Values**: ì •ì±… ì†ì‹¤, ê°€ì¹˜ ì†ì‹¤, ì—”íŠ¸ë¡œí”¼ ì†ì‹¤
- **Algorithm Specific**: ì•Œê³ ë¦¬ì¦˜ë³„ íŠ¹ìˆ˜ ë©”íŠ¸ë¦­ (KL divergence, alpha ê°’ ë“±)
- **Evaluation Results**: ì£¼ê¸°ì  í‰ê°€ ê²°ê³¼

### ë¡œì»¬ ê²°ê³¼ í™•ì¸

#### ê²°ê³¼ ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
results/
â”œâ”€â”€ experiment_name/
â”‚   â”œâ”€â”€ multi_seed_results.json    # ë©€í‹° ì‹œë“œ ìš”ì•½
â”‚   â”œâ”€â”€ seed_0/                    # ê°œë³„ ì‹œë“œ ê²°ê³¼
â”‚   â”‚   â”œâ”€â”€ model.pth              # í•™ìŠµëœ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ metrics.json           # ìƒì„¸ ë©”íŠ¸ë¦­
â”‚   â”‚   â””â”€â”€ config.yaml            # ì‚¬ìš©ëœ ì„¤ì •
â”‚   â””â”€â”€ wandb/                     # wandb ë¡œê·¸
```

#### JSON ê²°ê³¼ í™•ì¸
```bash
# ë©€í‹° ì‹œë“œ ìš”ì•½ í™•ì¸
cat results/cartpole_ppo/multi_seed_results.json | jq

# íŠ¹ì • ì‹œë“œ ë©”íŠ¸ë¦­ í™•ì¸  
cat results/cartpole_ppo/seed_0/metrics.json | jq
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ë³‘ë ¬ ì‹¤í—˜ ì‹¤í–‰
```bash
# ì„œë¡œ ë‹¤ë¥¸ GPUì—ì„œ ë™ì‹œ ì‹¤í–‰
CUDA_VISIBLE_DEVICES=0 bash scripts/overnight/cartpole_overnight.sh &
CUDA_VISIBLE_DEVICES=1 bash scripts/overnight/lunarlander_overnight.sh &

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
nohup bash scripts/overnight/halfcheetah_overnight.sh > halfcheetah_log.txt 2>&1 &
```

### ì‚¬ìš©ì ì •ì˜ ì„¤ì •
```bash
# íŠ¹ì • ì‹œë“œë¡œ ì‹¤í—˜
python -m main train --config config/cartpole/ppo.yaml --seed 1234

# GPU ì§€ì •
CUDA_VISIBLE_DEVICES=1 python -m main train --config config/lunarlander/sac.yaml

# CPU ê°•ì œ ì‚¬ìš©
python -m main train --config config/cartpole/ppo.yaml --device cpu
```

### Step ê¸°ë°˜ ë¡œê¹… (ì•Œê³ ë¦¬ì¦˜ ê³µì • ë¹„êµ)

**ì¤‘ìš”**: ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ì—ì„œ **ë™ì¼í•œ `step_log_interval`**ì„ ì‚¬ìš©í•´ì•¼ ê³µì •í•œ ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

```yaml
# ëª¨ë“  config íŒŒì¼ì—ì„œ ë™ì¼í•˜ê²Œ ì„¤ì •
logging:
  enable_step_logging: true
  step_log_interval: 1000  # ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ì—ì„œ ë™ì¼í•´ì•¼ í•¨
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
rl_framework/
â”œâ”€â”€ algorithms/          # 8ê°œ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜
â”‚   â”œâ”€â”€ ppo.py          # Proximal Policy Optimization
â”‚   â”œâ”€â”€ trpo.py         # Trust Region Policy Optimization  
â”‚   â”œâ”€â”€ a2c.py          # Advantage Actor-Critic
â”‚   â”œâ”€â”€ reinforce.py    # REINFORCE
â”‚   â”œâ”€â”€ sac.py          # Soft Actor-Critic
â”‚   â”œâ”€â”€ ddpg.py         # Deep Deterministic Policy Gradient
â”‚   â”œâ”€â”€ td3.py          # Twin Delayed DDPG
â”‚   â”œâ”€â”€ sql.py          # Soft Q-Learning
â”‚   â””â”€â”€ base.py         # ê¸°ë³¸ í´ë˜ìŠ¤ë“¤
â”œâ”€â”€ config/             # í™˜ê²½ë³„ ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ cartpole/       # CartPole í™˜ê²½ ì„¤ì •
â”‚   â”œâ”€â”€ lunarlander/    # LunarLander í™˜ê²½ ì„¤ì •
â”‚   â””â”€â”€ halfcheetah/    # HalfCheetah í™˜ê²½ ì„¤ì •
â”œâ”€â”€ environments/       # í™˜ê²½ ë˜í¼ë“¤
â”œâ”€â”€ networks/          # ì‹ ê²½ë§ ì•„í‚¤í…ì²˜
â”œâ”€â”€ scripts/           # ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ë“¤
â”‚   â”œâ”€â”€ overnight/     # í™˜ê²½ë³„ ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
â”‚   â”œâ”€â”€ tuning/        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
â”‚   â””â”€â”€ single/        # ë‹¨ì¼ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ train/             # í•™ìŠµ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”œâ”€â”€ utils/             # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â””â”€â”€ results/           # ì‹¤í—˜ ê²°ê³¼ë“¤
```

## ğŸ¯ ì‹¤í—˜ ì¶”ì²œ ì›Œí¬í”Œë¡œìš°

### 1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
```bash
# ë‹¨ì¼ ì‹œë“œë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸
python -m main train --config config/cartpole/ppo.yaml --seed 42
```

### 2. ì•ˆì •ì ì¸ ë²¤ì¹˜ë§ˆí‚¹
```bash
# ë©€í‹° ì‹œë“œë¡œ ì•ˆì •ì ì¸ ê²°ê³¼
python -m main multi --config config/cartpole/ppo.yaml --seeds 0 1 2 3 4
```

### 3. ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
```bash
# í™˜ê²½ë³„ ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
bash scripts/overnight/cartpole_overnight.sh
```

### 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
```bash
# ìµœê³  ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
bash scripts/tuning/ppo_tuning.sh cartpole
```

### 5. ê²°ê³¼ ë¶„ì„
```bash
# wandb dashboard í™•ì¸
# ë¡œì»¬ ì‹œê°í™” ìƒì„±
python -m main plot --plot_type step_comparison --comparison_dirs results/cartpole_ppo results/cartpole_sac --labels PPO SAC
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
# config íŒŒì¼ì—ì„œ batch_size ê°’ì„ ë‚®ì¶”ê¸° (ì˜ˆ: 256 â†’ 128)

# ë˜ëŠ” CPU ì‚¬ìš©
python -m main train --config config/cartpole/ppo.yaml --device cpu
```

#### wandb ë¡œê·¸ì¸ ë¬¸ì œ
```bash
# API í‚¤ ì¬ì„¤ì •
wandb login --relogin

# ì˜¤í”„ë¼ì¸ ëª¨ë“œ
export WANDB_MODE=offline
```

#### MuJoCo í™˜ê²½ ì˜¤ë¥˜
```bash
# MuJoCo ë¼ì´ì„¼ìŠ¤ í™•ì¸
# gymnasium[mujoco] ì¬ì„¤ì¹˜
pip install gymnasium[mujoco] --upgrade
```

#### ì‹œë®¬ë ˆì´ì…˜ GUI ë¬¸ì œ
- **ê°€ìƒë¨¸ì‹ **: GUIê°€ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ â†’ **ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰**
- **í—¤ë“œë¦¬ìŠ¤ ì„œë²„**: X11 forwarding ë˜ëŠ” VNC ì‚¬ìš©
- **Docker**: `--privileged -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix` ì˜µì…˜ ì‚¬ìš©

### ë¡œê·¸ í™•ì¸
```bash
# Python ì‹¤í–‰ ë¡œê·¸
tail -f nohup.out

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
watch nvidia-smi    # GPU ì‚¬ìš©ëŸ‰
htop               # CPU/Memory ì‚¬ìš©ëŸ‰
```

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- **[CLAUDE.md](CLAUDE.md)**: ê°œë°œìë¥¼ ìœ„í•œ ìƒì„¸ ê°€ì´ë“œ
- **[scripts/README.md](scripts/README.md)**: ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©ë²• ìƒì„¸ ì•ˆë‚´

## ğŸ¤ ê¸°ì—¬ ë° ë¬¸ì˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ê¸°ì—¬ëŠ” GitHub Issuesë¥¼ í†µí•´ ë‚¨ê²¨ì£¼ì„¸ìš”.

---

**Happy Reinforcement Learning! ğŸ¯**